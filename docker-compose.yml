services:
  # 训练服务 - 通过环境变量配置不同的内存需求
  train:
    image: chatglm-cpu-trainer
    container_name: chatglm-train
    volumes:
      - ./data:/app/data
      - ./models:/app/models
      - ~/.cache/huggingface:/root/.cache/huggingface  # 挂载Hugging Face缓存目录
    environment:
      - OMP_NUM_THREADS=${NUM_THREADS:-4}
      - MKL_NUM_THREADS=${NUM_THREADS:-4}
      - HF_ENDPOINT=https://hf-mirror.com
      - PYTHONPATH=/app
      - MEMORY_CONFIG=${MEMORY_CONFIG:-default}  # 可选: 4gb, 8gb, 16gb, 32gb
      - TRANSFORMERS_CACHE=/root/.cache/huggingface  # 设置模型缓存路径
    command: >
      python -m app.train 
      --model_name_or_path THUDM/chatglm2-6b 
      --dataset_path /app/data/input/dataset.txt 
      --output_dir /app/models/chatglm-lora
      --quantization ${QUANT_LEVEL:-4bit}
      --max_seq_length ${MAX_SEQ_LEN:-64}
      --max_samples ${MAX_SAMPLES:-200}
      --lora_r ${LORA_R:-8}
      --per_device_train_batch_size ${BATCH_SIZE:-1}
      --gradient_accumulation_steps ${GRAD_ACCUM:-16}
      --learning_rate ${LEARNING_RATE:-5e-5}
      --num_train_epochs ${NUM_EPOCHS:-3}
      ${MONITOR_MEMORY:+--monitor_memory}
      --memory_check_interval ${MEMORY_CHECK_INTERVAL:-60}
      --performance_log_steps ${PERFORMANCE_LOG_STEPS:-100}
    deploy:
      resources:
        limits:
          memory: ${MEMORY_LIMIT:-8G}
    restart: "no"

  # 预测服务
  predict:
    image: chatglm-cpu-trainer
    container_name: chatglm-predict
    volumes:
      - ./data:/app/data
      - ./models:/app/models
      - ~/.cache/huggingface:/root/.cache/huggingface  # 挂载Hugging Face缓存目录
    environment:
      - OMP_NUM_THREADS=${NUM_THREADS:-4}
      - MKL_NUM_THREADS=${NUM_THREADS:-4}
      - HF_ENDPOINT=https://hf-mirror.com
      - PYTHONPATH=/app
      - TRANSFORMERS_CACHE=/root/.cache/huggingface  # 设置模型缓存路径
    command: >
      python -m app.predict
      --model_path /app/models/chatglm-lora
      --base_model_path THUDM/chatglm2-6b
      --quantization ${QUANT_LEVEL:-4bit}
      --prompt "${PROMPT:-请介绍一下人工智能的发展历史。}"
      --max_length ${MAX_LENGTH:-1024}
    deploy:
      resources:
        limits:
          memory: ${MEMORY_LIMIT:-8G}
    restart: "no"